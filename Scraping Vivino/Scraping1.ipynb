{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scraping the search page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When logging this process we use the class connector from the scraping_class. But to use it for our purpose, there had to be made som changes.\n",
    "\n",
    "The changes:\n",
    "\n",
    "1) Change Connector_type to 'selenium'\n",
    "\n",
    "2) Insert path2selenium\n",
    "\n",
    "3) Insert code to scroll down on page to load more html content\n",
    "\n",
    "4) Return the connector.browser.page_source\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,os,time\n",
    "\n",
    "def ratelimit(dt):\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(dt) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='selenium',session=False,path2selenium='/Users/user/Downloads/chromedriver',n_tries = 5,timeout=30,waiting_time=0.5):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    self.waiting_time = waiting_time # define simple rate_limit parameter.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Chrome(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, fName used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit(self.waiting_time)\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          self.log.flush()\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "          self.log.flush()\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit(self.waiting_time)\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      \n",
    "      # Slowly scrolling down the page, in order to load more \n",
    "      y = 1000\n",
    "      for timer in range(0,2000):\n",
    "          self.browser.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "          y += 1000  \n",
    "          time.sleep(3)\n",
    "        \n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "      self.log.flush()\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "      html=connector.browser.page_source\n",
    "      return html,call_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selenium request\n",
    "\n",
    "The Vivino page has a search page, with opportunity to filter on different variables. We chose to filter on red wines from Italy and the price was set to be 0-2500+. This gave us 99 841 wines, and we were far from collecting information on them all, since scrolling usually stopped after 3000 wines, and it was time consuming. \n",
    "The page had to either be sorted by ratings, price, discount or popularity.\n",
    "So we did it over several links, where we changed the way they were sorted by, to get wines from various price and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define logfile \n",
    "logfile = 'logfile_wine.csv' ## name your log file.\n",
    "connector = Connector(logfile)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Insert a URL of the search page\n",
    "url = 'https://www.vivino.com/explore?e=eJwNijEOgCAQBH-zNZpYXmfHE4wxJyK5RMDABfX30swUM7HQgCiJDCK_NE7GwH00W7gOi7vncFLjIl75Qt6psEoKdePmCwePTIevDo8ua5_dV7tFfwGHHeQ='\n",
    "\n",
    "# Connector class returns html and call_id\n",
    "html, call_id =connector.get(url,\"Searchpage\")\n",
    "\n",
    "# parse the html to a soup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exstracting from soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toscana 2008</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/masseto-toscana/w/24467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toscana 2006</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/masseto-toscana/w/24467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toscana 2015</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/masseto-toscana/w/24467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toscana 2009</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/masseto-toscana/w/24467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toscana 2007</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/masseto-toscana/w/24467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>Farnito Cabernet Sauvignon Toscana 2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>https://www.vivino.com/carpineto-farnito-caber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>Morellino di Scansano 2017</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Morellino di Scansano</td>\n",
       "      <td>https://www.vivino.com/fattoria-le-pupille-mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>Barbera d'Alba 2016</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Barbera d'Alba</td>\n",
       "      <td>https://www.vivino.com/pio-cesare-barbera-d-al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Bricco Ambrogio Barolo 2014</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>https://www.vivino.com/lodali-barolo-bricco-am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Vigneto Pozzare Cabernet 2016</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Colli Berici</td>\n",
       "      <td>https://www.vivino.com/piovene-porto-godi-vign...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name rating                 region  \\\n",
       "0                                Toscana 2008    4.7                Toscana   \n",
       "1                                Toscana 2006    4.8                Toscana   \n",
       "2                                Toscana 2015    4.7                Toscana   \n",
       "3                                Toscana 2009    4.7                Toscana   \n",
       "4                                Toscana 2007    4.7                Toscana   \n",
       "...                                       ...    ...                    ...   \n",
       "1932  Farnito Cabernet Sauvignon Toscana 2010    4.0                Toscana   \n",
       "1933               Morellino di Scansano 2017    3.6  Morellino di Scansano   \n",
       "1934                      Barbera d'Alba 2016    3.8         Barbera d'Alba   \n",
       "1935              Bricco Ambrogio Barolo 2014    4.2                 Barolo   \n",
       "1936            Vigneto Pozzare Cabernet 2016    3.8           Colli Berici   \n",
       "\n",
       "                                                   link  \n",
       "0     https://www.vivino.com/masseto-toscana/w/24467...  \n",
       "1     https://www.vivino.com/masseto-toscana/w/24467...  \n",
       "2     https://www.vivino.com/masseto-toscana/w/24467...  \n",
       "3     https://www.vivino.com/masseto-toscana/w/24467...  \n",
       "4     https://www.vivino.com/masseto-toscana/w/24467...  \n",
       "...                                                 ...  \n",
       "1932  https://www.vivino.com/carpineto-farnito-caber...  \n",
       "1933  https://www.vivino.com/fattoria-le-pupille-mor...  \n",
       "1934  https://www.vivino.com/pio-cesare-barbera-d-al...  \n",
       "1935  https://www.vivino.com/lodali-barolo-bricco-am...  \n",
       "1936  https://www.vivino.com/piovene-porto-godi-vign...  \n",
       "\n",
       "[1937 rows x 4 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Finding the needed information in the soup and makes a dataframe\n",
    "\n",
    "soup_select = soup.find_all('div', {'class': 'explorerCard__explorerCard--3Q7_0 explorerPageResults__explorerCard--3q6Qe'})\n",
    "vivino='https://www.vivino.com'\n",
    "urls=[]\n",
    "names=[]\n",
    "ratings=[]\n",
    "region=[]\n",
    "\n",
    "for i in soup_select:\n",
    "    # find all a tags -connoting a hyperlink.\n",
    "    links = i.find_all('a', {'class': 'anchor__anchor--2QZvA'}) \n",
    "    #  Save the links constructed in the urls list\n",
    "    urls.append([vivino+link['href'] for link in links if link.has_attr('href')][0])\n",
    "    # Saving wine titles in names\n",
    "    names.append(i.find_all('span', {'class': 'vintageTitle__wine--U7t9G'})[0].text)\n",
    "    # Saving total rating in ratings\n",
    "    ratings.append(i.find_all('div', {'class': 'vivinoRatingWide__averageValue--1zL_5'})[0].text)\n",
    "    # Saving region of the wine\n",
    "    region.append(i.find_all('a', {'class': 'anchor__anchor--2QZvA vintageLocation__anchor--T7J3k'})[2].text)\n",
    "\n",
    "'''The list are zipped and saved to a dataframe for later use. We applied drop_duplicates by link\n",
    "to avoid having to have two of the same wines in our dataset. The dataframe is then saved if needed.'''\n",
    "\n",
    "df=pd.DataFrame(zip(names,ratings,region,urls),columns=['name','rating','region','link'])\n",
    "vivino=df.drop_duplicates().reset_index(drop=True)\n",
    "#vivino.to_csv('vivino_random.csv')\n",
    "\n",
    "vivino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally: if two dataframes have to be merged to create a big dataframe\n",
    "\n",
    "#Load the other dataframe/dataframes\n",
    "df_loaded=pd.read_csv('Insert file name.csv', index_col=[0])\n",
    "\n",
    "# Merging two dataframes\n",
    "merged=pd.concat([df_loaded,vivino])\n",
    "\n",
    "#drop duplicates and reset index \n",
    "df3=merged.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Save the merged dataframe \n",
    "df3.to_csv('Insert filename of your choice.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
